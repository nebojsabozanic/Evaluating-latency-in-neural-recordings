{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Convert Matlab code to Python notebook, place it on Git and share it via Google Colab\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def poissonGenKreuz(nSpikes, T):\n",
    "\n",
    "    uniform = np.random.rand(1, nSpikes)\n",
    "    spikes = -np.log(1-uniform)/(nSpikes/T)\n",
    "    spikes = np.cumsum(spikes)\n",
    "    spikes = spikes - min(spikes)\n",
    "    spikes = T*spikes/max(spikes)\n",
    "    return spikes\n",
    "\n",
    "\n",
    "def switch(case, spikes, nSpikes, T, jit):\n",
    "    return {\n",
    "        'same': spikes[0],\n",
    "        'different': poissonGenKreuz(nSpikes, T),\n",
    "        'same with some noise': spikes[0] + jit\n",
    "    }.get(case, None)\n",
    "\n",
    "\n",
    "def latency_cross(nBin, noiseLevelj):\n",
    "    # jitter should be from 0 to 1; fool proof later\n",
    "    # Determining the latency using spike train metrics\n",
    "    # started April Fool 2015\n",
    "    # @Nebojsa @Mario @Thomas d_KreuzLab_b\n",
    "\n",
    "    nStats = 100\n",
    "    nSpikes = 1000\n",
    "\n",
    "    T = 100\n",
    "\n",
    "    # noiseLevelj = 0.1;\n",
    "    noiseLeveld = 0\n",
    "    noiseLevela = 0\n",
    "\n",
    "    # rate is defined as nSpikes/T\n",
    "\n",
    "    # modify to a point Spike_distance in order to cover the edge\n",
    "    tauStep = T / nBin # .01\n",
    "    Tau = np.arange(-T / 2, T / 2, tauStep)\n",
    "\n",
    "    T_d = np.zeros([len(Tau)])\n",
    "    Tc_d = np.zeros([len(Tau)])\n",
    "    Tv_d = np.zeros([len(Tau)])\n",
    "\n",
    "    cases = ['same', 'different', 'same with some noise']\n",
    "    doit = cases[2]\n",
    "\n",
    "    spikes = np.empty((2,), dtype=object)\n",
    "\n",
    "    for i in range(nStats):\n",
    "\n",
    "        # print(i)\n",
    "        ## spikes{0} = poissonSpikeGen(nSpikes / T, T) omit?@###\n",
    "        spikes[0] = poissonGenKreuz(nSpikes, T)\n",
    "\n",
    "        jit = np.sort(np.random.rand(len(spikes[0])))\n",
    "        if (noiseLevelj):\n",
    "            jit = noiseLevelj * T / nSpikes * jit / max(jit)\n",
    "        else:\n",
    "            jit = np.zeros(len(jit))\n",
    "        jit[0] = abs(jit[0])\n",
    "        jit[-1] = -abs(jit[-1])\n",
    "\n",
    "        ref_spikes = switch(doit, spikes, nSpikes, T, jit)\n",
    "\n",
    "        C_c = np.zeros(len(Tau))\n",
    "        S_d = np.zeros(len(Tau))\n",
    "        V_c = np.zeros(len(Tau))\n",
    "\n",
    "        for count in range(len(Tau)):\n",
    "            print(count)\n",
    "            spikes[1] = ref_spikes + Tau[count]\n",
    "            # (i-1)/nStats*100 + (count-1)/len(Tau)*100/nStats\n",
    "\n",
    "            # # save test.mat spikes Tau count ?\n",
    "            # temp = spkDistance2(spikes, max(0, Tau(count)), min(T, T + Tau(count)), [0, Tau(count)], [T, T + Tau(count)])\n",
    "            # tauStep = (min(T, T + Tau(count)) - max(0, Tau(count))) / nBin\n",
    "            # psth[0] = histc(spikes[0], max(0, Tau(count)): tauStep: min(T, T + Tau(count)))\n",
    "            # psth[1] = histc(spikes[1], max(0, Tau(count)): tauStep: min(T, T + Tau(count)))  # tauStep\n",
    "            # R = corrcoef(psth[0][:-1), psth[1][:-1])\n",
    "            # vc = SPIKY_Victor_MEX(spikes[0], spikes[1], 100)  # put as an argument 100\n",
    "\n",
    "            C_c[count] = 1  # R[0, 1]\n",
    "            S_d[count] = 2  # temp\n",
    "            V_c[count] = 3  # vc\n",
    "\n",
    "        T_d = T_d + S_d  # make a matrix\n",
    "        Tc_d = Tc_d + C_c  # make a matrix\n",
    "        Tv_d = Tv_d + V_c  # make a matrix\n",
    "\n",
    "    normT_d = (T_d/nStats - np.mean(T_d/nStats))/np.std(T_d/nStats)\n",
    "    normTc_d = -(Tc_d/nStats - np.mean(Tc_d/nStats))/np.std(Tc_d/nStats)\n",
    "    normTv_d = (Tv_d/nStats - np.mean(Tv_d/nStats))/np.std(Tv_d/nStats)\n",
    "    # plot(Tau, normT_d, 'k', Tau, normTc_d, 'm')\n",
    "    # title(str2num(nSpikes / tauStep))\n",
    "    # size(T_d);\n",
    "    b = [np.mean(T_d/nStats)- np.mean(Tc_d/nStats), np.std(T_d/nStats), np.std(Tc_d/nStats)]\n",
    "    b[0] = normT_d[(len(normT_d) + 1) // 2]  # middle value\n",
    "    b[1] = normTc_d[(len(normTc_d) + 1) // 2]\n",
    "    b[2] = normTv_d[(len(normTv_d) + 1) // 2]\n",
    "\n",
    "    return b\n",
    "\n",
    "# nBin = np.arange(50,500,50) # 10**np.arange(1,3)\n",
    "nBin = 100\n",
    "jitter = np.array([0, 0.05, 0.1, 0.2, 0.4, 0.8, 1.6])\n",
    "spkDistv = np.zeros(np.size(jitter))\n",
    "crosscorv = np.zeros(np.size(jitter))\n",
    "vp = np.zeros(np.size(jitter))\n",
    "\n",
    "for count, val in enumerate(jitter):\n",
    "    print(count)\n",
    "\n",
    "    b = latency_cross(nBin, jitter[count])\n",
    "    spkDistv[count] = b[0]\n",
    "    crosscorv[count] = b[1]\n",
    "    vp[count] = b[2]\n",
    "\n",
    "plt.plot(jitter, spkDistv, jitter, crosscorv, jitter, vp)\n",
    "#plt.legend((\"SPIKE-distance\", \"Cross-correlation\", \"Victor Purpura\"))\n",
    "#plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('Amplitude of the peak')\n",
    "plt.xlabel('Jitter')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}